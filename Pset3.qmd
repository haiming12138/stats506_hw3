---
title: 'STATS 506 Problem Set #3'
author: 'Haiming Li'
format: 
  html:
    toc: true
  pdf: default
---
## Vision
a. Read data and merge data
```{r 1a}
library(haven)
vix <- read_xpt('./VIX_D.XPT')
demo <- read_xpt('./DEMO_D.XPT')
df <- merge(vix, demo, by='SEQN')
cat('Sample size:', nrow(df))
```
b. The max age is 85, so there will only be 9 age brackets.
```{r 1b, warning=FALSE, message=FALSE}
library(dplyr)
df <- subset(df, (VIQ220 == 1) | (VIQ220 == 2))
df$VIQ220 <- ifelse(is.na(df$VIQ220), 0, df$VIQ220)
age_groups <- c('10-19' ,'20-29', '30-39', '40-49',
                '50-59', '60-69', '70-79', '80-89')
df$age_cat <- age_groups[floor(df$RIDAGEYR / 10)]
res <- df %>% group_by(age_cat) %>% 
          summarise(proportion = round(100 * mean(VIQ220 == 1, na.rm=TRUE), 2))
knitr::kable(res, 'simple', col.names = c('Age Group', 'Proportion'))
```
c. Here are fitted models and their summary.
```{r 1c}
#' Create Summary Table for Logistic Regression
#'
#' @param model a fitted logistic regression model
#' @return a table with required stats
summary_table <- function(model) {
  odds_ratios <- as.data.frame(t(exp(coef(model))))
  res <- data.frame(
  'Sample Size' = nobs(model),        
  'Pseudo R2' = 1 - model$deviance / model$null.deviance,  
  'AIC' = AIC(model) 
  )
  res <- cbind(odds_ratios, res)
  return(t(res))
}

# data cleaning
df_mod <- subset(df, select=c(VIQ220, RIAGENDR, RIDAGEYR, RIDRETH1, INDFMPIR))
df_mod <- na.omit(df_mod)
df_mod$VIQ220 <- as.factor(df_mod$VIQ220)
df_mod$RIAGENDR <- as.factor(df_mod$RIAGENDR)
df_mod$RIDRETH1 <- as.factor(df_mod$RIDRETH1)

# model fitting
mod1 <- glm(VIQ220 ~ RIDAGEYR, data = df_mod, 
            family = binomial(link = 'logit'))
knitr::kable(summary_table(mod1))
mod2 <- glm(VIQ220 ~ RIDAGEYR + RIDRETH1 + RIAGENDR, data = df_mod, 
            family = binomial(link = 'logit'))
knitr::kable(summary_table(mod2))
mod3 <- glm(VIQ220 ~ RIDAGEYR + RIDRETH1 + RIAGENDR + INDFMPIR, data = df_mod, 
            family = binomial(link = 'logit'))
knitr::kable(summary_table(mod3))
```
d. From previous part, we have the odds ratio for women is 0.5967415. This can be interpreted as the value of female odds divided by male odds. From the summary of model 3, the coefficient is significant, thus implying that female odds differs from male odds for being a glass wearer is statistically significant. Since the positive class of glm is the last level of the factor, 2 in this case, the positive class for the model is actually 'not a glass wearer'. Thus, we need to invert our interpretation. Having an odds ratio less than 1 from the model actually should imply that the odds of females wearing glasses/contacts for distance vision is higher than male.
```{r}
summary(mod3)
```
As shown by the two sample proportion test, the p-value is extremely small. Thus, we can reject the null hypothesis and conclude that the proportion of wearers of glasses/contact lenses for distance vision differs between men and women. We can even say that male proportion is less than female proportion. (according to the fact that the confidence interval is below 0)
```{r}
tab <- table(df_mod$RIAGENDR, df_mod$VIQ220)
prop.test(tab[,1], rowSums(tab))
```

## Sakila
a. It appears that all movies are from 2006, which is the earliest release year from this database.
```{r 2a, echo=TRUE, results='hide', warning=FALSE}
library(DBI)
sakila <- dbConnect(RSQLite::SQLite(), './sakila_master.db')
dbGetQuery(sakila,'
  SELECT film_id, title, release_year
  FROM film
  ORDER BY release_year ASC
')
```
b. Here's the R approach, note that the min value is unique.
```{r 2br}
film_cat <- dbGetQuery(sakila, 'SELECT * FROM film_category')
category <-  dbGetQuery(sakila, 'SELECT * FROM category')
cat_count <- table(film_cat$category_id)
min_cat <- which.min(cat_count)
cat(category$name[category$category_id == min_cat], cat_count[min_cat])
```
Here's the SQL approach
```{r 2bsql}
dbGetQuery(sakila, '
  SELECT c.name, COUNT(*) AS count
  FROM film_category AS fc
  JOIN category AS c
  ON fc.category_id = c.category_id
  GROUP BY c.category_id
  ORDER BY count ASC
  LIMIT 1
')
```
c. Here's the R approach
```{r 2cr, warning=FALSE}
customer <- dbGetQuery(sakila, 'SELECT * FROM customer')
address <- dbGetQuery(sakila, 'SELECT * FROM address')
city <- dbGetQuery(sakila, 'SELECT * FROM city')
country <- dbGetQuery(sakila, 'SELECT * FROM country')
merged_df <- merge(customer, address, by='address_id')
merged_df <- merge(merged_df, city, by='city_id')
merged_df <- merge(merged_df, country, by='country_id')
res <- table(merged_df$country)
res[res == 13]
```

Here's the SQL approach.
```{r 2csql}
dbGetQuery(sakila, '
  SELECT country.country, COUNT(*) AS count
  FROM customer, address, city, country
  WHERE customer.address_id = address.address_id AND
    address.city_id = city.city_id AND
    city.country_id = country.country_id
  GROUP BY country.country_id
  HAVING count = 13
')
```

## US Records
a. Here's the proportion of TLD with ``.com'
```{r 3a}
df <- read.csv('./us-500.csv')
cat('Proportion of .com:', mean(grepl('\\.com$', df$email)))
```
b. Here's the proportion of email with at least one non alphanumeric character in them. Since it's possible to have ``.' in the username, we need to seperate the username and domain, then check each part separately.
```{r 3b}
emails <- strsplit(df$email, '@')
usernames <- lapply(emails, '[[', 1)
domains <- lapply(emails, '[[', 2)
domains <- gsub('\\.[a-z]{3}', '', domains)
mean(grepl('[^a-zA-Z0-9]+', usernames) | grepl('[^a-zA-Z0-9]+', domains))
```
c. Here's the top 5 area code. Notice that there is no ties in top 5, so I can directly use the top 5 element.
```{r 3c}
res <- table(c(substr(df$phone1, 1, 3), substr(df$phone2, 1, 3)))
sort(res, decreasing=TRUE)[1:5]
```
d. Here's the frequency histogram of the apartment numbers.
```{r 3d, fig.align='center'}
apt_nbrs <- regmatches(df$address, regexpr('[0-9]+$', df$address))
hist(log(as.numeric(apt_nbrs)), main = 'Frequency of Apartment Numbers', 
     xlab = 'log(Apartment Number)')
```
e. The data appears to be synthetic, as the first digit does not have a decreasing trend.
```{r 3e}
first_digit <- as.numeric(substring(apt_nbrs, 1, 1))
hist(first_digit, main = 'First Digit Distribution', xlab = '', freq = FALSE)
```

## Citaton & Link to GitHub
* [Logistic Regression Positive Class in R](https://stackoverflow.com/questions/72121373/tidymodels-not-treating-first-factor-level-as-positive-class)
* [Interpretation of LR coefficients](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/)
* [GitHub Repo of this Pset](https://github.com/haiming12138/stats506_hw3.git)


